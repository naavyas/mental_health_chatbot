{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2ar1w-bud2W"
      },
      "source": [
        "#Creating a better, more realistic chatbot using machine learning\n",
        "\n",
        "In our last notebook, we looked at ELIZA, one of the first chatbots ever created, and we designed our own version of ELIZA. \n",
        "\n",
        "As you probably saw, the chatbot that we created was OK, but it definitely wasn't as good as something like Alexa or Siri. What's the next step that we can take to make our chatbot look more like something that we'd see today?\n",
        "\n",
        "In this notebook, we'll explore how to use sequential neural networks for our chatbots, in order to improve their functionality and make them more realistic.\n",
        "\n",
        "Before we start, here are a set of [slides](https://docs.google.com/presentation/d/1ykLNZNkql0SDqqDiNLKJVspUFhVLKB_7x-uB7sSlbNI/edit?usp=sharing) on NLP that might be a useful resource to go over, to make sure that we have some of the prerequisite background knowledge necessary for our project. \n",
        "\n",
        "![link](https://hackernoon.com/hn-images/1*5zQ_G4mZhB-4q-V9PhI0xQ.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T00ekjwglhCg"
      },
      "source": [
        "###Outline\n",
        "\n",
        "This'll be the outline of our notebook for today!\n",
        "\n",
        "1. Exploring our language data\n",
        "2. From language to information: preprocessing methods\n",
        "2. Modeling our data with a sequential neural network (RNN/LSTM)\n",
        "4. Evaluation -- so how's our chatbot looking?\n",
        "5. **Challenge**: Deep dive into the inner workings of the LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjDbmBt0qYF0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4e42396-049b-453b-bb15-286b46b9fdf9"
      },
      "source": [
        "#@title Run this code to get started! This'll load some packages and set up some dependencies for us\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import spacy\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers , activations , models , preprocessing, utils\n",
        "from keras import Input, Model\n",
        "from keras.activations import softmax\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras_preprocessing.text import Tokenizer\n",
        "tf.random.set_seed(1)\n",
        "from google.colab import drive\n",
        "import time\n",
        "import os\n",
        "import gdown\n",
        "import nltk\n",
        "\n",
        "# set pandas viewing options\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option(\"max_colwidth\", None)\n",
        "#pd.reset_option(\"max_colwidth\")\n",
        "\n",
        "# the source of our data is: https://github.com/nbertagnolli/counsel-chat\n",
        "\n",
        "# load our weights\n",
        "#gdown.download('https://drive.google.com/uc?export=download&id=1212a1k_GxYbvh-CKF6m9oLwAb_ZBRkZe','chatbot_seq2seq_v3.h5',True);\n",
        "!wget 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Mental%20Health%20Chatbots/chatbot_seq2seq_v3.h5'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-31 04:00:33--  https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Mental%20Health%20Chatbots/chatbot_seq2seq_v3.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.128, 142.250.157.128, 142.251.8.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44061792 (42M) [application/octet-stream]\n",
            "Saving to: ‘chatbot_seq2seq_v3.h5’\n",
            "\n",
            "chatbot_seq2seq_v3. 100%[===================>]  42.02M  27.4MB/s    in 1.5s    \n",
            "\n",
            "2021-12-31 04:00:35 (27.4 MB/s) - ‘chatbot_seq2seq_v3.h5’ saved [44061792/44061792]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXyczgPYqo5K"
      },
      "source": [
        "## Preparing our dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKWuQtadRh9j"
      },
      "source": [
        "We are going to be working with data from CounselChat (https://counselchat.com/), which is an online resource where people can ask questions and get answers from licensed mental health counselors. We are going to take a look at some of the questions that people asked on this site, see what the counselors responded with, and create a chatbot that'll try to do the same thing.\n",
        "\n",
        "[**TW:** suicidal ideation] \n",
        "\n",
        "**Disclaimer**: This dataset was made freely available and all data was provided consensually, and in anonymized form. When working with sensitive data such as medical data, you should *always* get permission first!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCXZR79CSmrb"
      },
      "source": [
        "#@title Run this cell to download our dataset\n",
        "chat_data = pd.read_csv(\"https://raw.githubusercontent.com/nbertagnolli/counsel-chat/master/data/20200325_counsel_chat.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cyiR_psR7l2"
      },
      "source": [
        "###Exploring our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4RZK8PrR9cV"
      },
      "source": [
        "We should begin by getting a sense of what data we are working with. Our data is in a pandas dataframe named `chat_data`.\n",
        "\n",
        "**Exercise**: Print out the first 5 rows in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8Nv3ehoyuVE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "11878a8d-3f10-44c2-9ed2-9811fe6bd59d"
      },
      "source": [
        "## YOUR CODE HERE\n",
        "chat_data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7f0a9a80-b875-496b-9456-6eac8ccb4e1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>questionID</th>\n",
              "      <th>questionTitle</th>\n",
              "      <th>questionText</th>\n",
              "      <th>questionLink</th>\n",
              "      <th>topic</th>\n",
              "      <th>therapistInfo</th>\n",
              "      <th>therapistURL</th>\n",
              "      <th>answerText</th>\n",
              "      <th>upvotes</th>\n",
              "      <th>views</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone</td>\n",
              "      <td>depression</td>\n",
              "      <td>Sherry Katz, LCSWCouples and Family Therapist, LCSW</td>\n",
              "      <td>https://counselchat.com/therapists/sherry-katz-lcsw</td>\n",
              "      <td>If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media.  Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living.  They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible.   Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.</td>\n",
              "      <td>1</td>\n",
              "      <td>2899</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone</td>\n",
              "      <td>depression</td>\n",
              "      <td>Robin Landwehr, DBH, LPCC, NCCMental Health in a Primary Care Setting</td>\n",
              "      <td>https://counselchat.com/therapists/robin-landwehr-dbh-lpcc-ncc</td>\n",
              "      <td>Hello, and thank you for your question and seeking advice on this. Feelings of worthlessness is unfortunately common. In fact, most people, if not all, have felt this to some degree at some point in their life. You are not alone. Changing our feelings is like changing our thoughts - it's hard to do. Our minds are so amazing that the minute you change your thought another one can be right there to take it's place. Without your permission, another thought can just pop in there. The new thought may feel worse than the last one! My guess is that you have tried several things to improve this on your own even before reaching out on here. People often try thinking positive thoughts, debating with their thoughts, or simply telling themselves that they need to \"snap out of it\" - which is also a thought that carries some self-criticism. Some people try a different approach, and there are counselors out there that can help you with this. The idea is that instead of trying to change the thoughts, you change how you respond to them. You learn skills that allow you to manage difficult thoughts and feelings differently so they don't have the same impact on you that they do right now. For some people, they actually DO begin to experience less hurtful thoughts once they learn how to manage the ones they have differently. Acceptance and Commitment Therapy may be a good choice for you. There is information online and even self-help books that you can use to teach you the skills that I mentioned. Because they are skills, they require practice, but many people have found great relief and an enriched life by learning them. As for suicidal thoughts, I am very glad to read that this has not happened to you. Still, you should watch out for this because it can be a sign of a worsening depression. If you begin to think about this, it is important to reach out to a support system right away. The National Suicide Prevention Lifeline is 1-800-273-8255. The text line is #741741. I hope some other colleagues will provide you more suggestions. Be well...Robin Landwehr, DBH, LPCC</td>\n",
              "      <td>1</td>\n",
              "      <td>3514</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone</td>\n",
              "      <td>depression</td>\n",
              "      <td>Lee KingI use an integrative approach to treatment and have an online therapy practice.</td>\n",
              "      <td>https://counselchat.com/therapists/lee-king</td>\n",
              "      <td>First thing I'd suggest is getting the sleep you need or it will impact how you think and feel. I'd look at finding what is going well in your life and what you can be grateful for. I believe everyone has talents and wants to find their purpose in life. I think you can figure it out with some help.</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone</td>\n",
              "      <td>depression</td>\n",
              "      <td>Shauntai Davis-YearginPersonalized, private online counseling for individuals and couples</td>\n",
              "      <td>https://counselchat.com/therapists/shauntai-davis-yeargin</td>\n",
              "      <td>Therapy is essential for those that are feeling depressed and worthless. When I work with those that are experiencing concerns related to feeling of depression and issues with self esteem. I generally work with my client to help build coping skills to reduce level of depression and to assist with strengthening  self esteem, by guiding my client with CBT practices. CBT helps with gaining a better awareness of how your thought process influences your belief system, and how your beliefs impact your actions and the outcome of your behaviors.  This process isn’t easy but it helps teach an individual that we don’t always have control over what happens in our lives but we can control how we interpret, feel, and behave. CBT is good for individuals dealing with depression, anxiety, toxic relationships, stress, self esteem, codependency, etc.</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone</td>\n",
              "      <td>depression</td>\n",
              "      <td>Jordan WhiteLicensed Social Worker at Oak Roots Dynamic</td>\n",
              "      <td>https://counselchat.com/therapists/jordan-white</td>\n",
              "      <td>I first want to let you know that you are not alone in your feelings and there is always someone there to help. You can always change your feelings and change your way of thinking by being open to trying to change. You can always make yourself available to learning new things or volunteering so that you can make a purpose for yourself.</td>\n",
              "      <td>0</td>\n",
              "      <td>620</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f0a9a80-b875-496b-9456-6eac8ccb4e1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f0a9a80-b875-496b-9456-6eac8ccb4e1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f0a9a80-b875-496b-9456-6eac8ccb4e1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  questionID  \\\n",
              "0           0           0   \n",
              "1           1           0   \n",
              "2           2           0   \n",
              "3           3           0   \n",
              "4           4           0   \n",
              "\n",
              "                                             questionTitle  \\\n",
              "0  Can I change my feeling of being worthless to everyone?   \n",
              "1  Can I change my feeling of being worthless to everyone?   \n",
              "2  Can I change my feeling of being worthless to everyone?   \n",
              "3  Can I change my feeling of being worthless to everyone?   \n",
              "4  Can I change my feeling of being worthless to everyone?   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                 questionText  \\\n",
              "0  I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?   \n",
              "1  I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?   \n",
              "2  I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?   \n",
              "3  I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?   \n",
              "4  I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?   \n",
              "\n",
              "                                                                               questionLink  \\\n",
              "0  https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone   \n",
              "1  https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone   \n",
              "2  https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone   \n",
              "3  https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone   \n",
              "4  https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone   \n",
              "\n",
              "        topic  \\\n",
              "0  depression   \n",
              "1  depression   \n",
              "2  depression   \n",
              "3  depression   \n",
              "4  depression   \n",
              "\n",
              "                                                                               therapistInfo  \\\n",
              "0                                        Sherry Katz, LCSWCouples and Family Therapist, LCSW   \n",
              "1                      Robin Landwehr, DBH, LPCC, NCCMental Health in a Primary Care Setting   \n",
              "2    Lee KingI use an integrative approach to treatment and have an online therapy practice.   \n",
              "3  Shauntai Davis-YearginPersonalized, private online counseling for individuals and couples   \n",
              "4                                    Jordan WhiteLicensed Social Worker at Oak Roots Dynamic   \n",
              "\n",
              "                                                     therapistURL  \\\n",
              "0             https://counselchat.com/therapists/sherry-katz-lcsw   \n",
              "1  https://counselchat.com/therapists/robin-landwehr-dbh-lpcc-ncc   \n",
              "2                     https://counselchat.com/therapists/lee-king   \n",
              "3       https://counselchat.com/therapists/shauntai-davis-yeargin   \n",
              "4                 https://counselchat.com/therapists/jordan-white   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           answerText  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media.  Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living.  They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible.   Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.   \n",
              "1  Hello, and thank you for your question and seeking advice on this. Feelings of worthlessness is unfortunately common. In fact, most people, if not all, have felt this to some degree at some point in their life. You are not alone. Changing our feelings is like changing our thoughts - it's hard to do. Our minds are so amazing that the minute you change your thought another one can be right there to take it's place. Without your permission, another thought can just pop in there. The new thought may feel worse than the last one! My guess is that you have tried several things to improve this on your own even before reaching out on here. People often try thinking positive thoughts, debating with their thoughts, or simply telling themselves that they need to \"snap out of it\" - which is also a thought that carries some self-criticism. Some people try a different approach, and there are counselors out there that can help you with this. The idea is that instead of trying to change the thoughts, you change how you respond to them. You learn skills that allow you to manage difficult thoughts and feelings differently so they don't have the same impact on you that they do right now. For some people, they actually DO begin to experience less hurtful thoughts once they learn how to manage the ones they have differently. Acceptance and Commitment Therapy may be a good choice for you. There is information online and even self-help books that you can use to teach you the skills that I mentioned. Because they are skills, they require practice, but many people have found great relief and an enriched life by learning them. As for suicidal thoughts, I am very glad to read that this has not happened to you. Still, you should watch out for this because it can be a sign of a worsening depression. If you begin to think about this, it is important to reach out to a support system right away. The National Suicide Prevention Lifeline is 1-800-273-8255. The text line is #741741. I hope some other colleagues will provide you more suggestions. Be well...Robin Landwehr, DBH, LPCC   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         First thing I'd suggest is getting the sleep you need or it will impact how you think and feel. I'd look at finding what is going well in your life and what you can be grateful for. I believe everyone has talents and wants to find their purpose in life. I think you can figure it out with some help.   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Therapy is essential for those that are feeling depressed and worthless. When I work with those that are experiencing concerns related to feeling of depression and issues with self esteem. I generally work with my client to help build coping skills to reduce level of depression and to assist with strengthening  self esteem, by guiding my client with CBT practices. CBT helps with gaining a better awareness of how your thought process influences your belief system, and how your beliefs impact your actions and the outcome of your behaviors.  This process isn’t easy but it helps teach an individual that we don’t always have control over what happens in our lives but we can control how we interpret, feel, and behave. CBT is good for individuals dealing with depression, anxiety, toxic relationships, stress, self esteem, codependency, etc.   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   I first want to let you know that you are not alone in your feelings and there is always someone there to help. You can always change your feelings and change your way of thinking by being open to trying to change. You can always make yourself available to learning new things or volunteering so that you can make a purpose for yourself.   \n",
              "\n",
              "   upvotes  views  split  \n",
              "0        1   2899  train  \n",
              "1        1   3514  train  \n",
              "2        0      5  train  \n",
              "3        0     31  train  \n",
              "4        0    620  train  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EMPW6UQzLTa"
      },
      "source": [
        "**Question**: Which columns correspond to the question that the person asked? Which columns correspond to the answer that the mental health counselor gave?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1adKDOeMz3Iu"
      },
      "source": [
        "Now, let's see how many questions and answers there are in each topic!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IImBBdYu0Qz3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "4ed6b358-057c-4b27-a161-9e3f1e64ef21"
      },
      "source": [
        "#@title Run this cell to plot the number of questions and answers for each topic\n",
        "\n",
        "chat_data[\"topic\"].value_counts().plot.bar()\n",
        "plt.title(\"Number of questions and answers for each topic\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehqy_t5BUWqQ"
      },
      "source": [
        "**Question**: Which topics are most popular? Which topics are least popular? Why do you think that is?\n",
        "\n",
        "**Question**: Why might there be bias towards / against certain topics in this dataset?\n",
        "\n",
        "**Note**: As usual, remember to be kind and empathetic toward your fellow classmates! This may be a personal topic for some."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a9k7TT91JIc"
      },
      "source": [
        "We want to train our chatbot to respond to users' questions with answers, in a similar fashion to how mental health counselors respond to people's questions on CounselChat. First, let's extract just the data we need for our model.\n",
        "\n",
        "**Exercise**: What should the `X` be for our model? What should the `y` be? Fill in the code below with the necessary columns of our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOZZhVB91at0"
      },
      "source": [
        "# YOUR CODE HERE:\n",
        "X = chat_data['questionText'] # TODO: replace None with the columns we should assign to X\n",
        "y = chat_data['answerText'] # TODO: replace None with the columns we should assign to Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEmfpNtfiA-e"
      },
      "source": [
        "###Cleaning our data\n",
        "\n",
        "We have our data now! But as you've probably noticed we have *language* data. A computer doesn't understand what language data means; to a computer, a word is just a bunch of letters. We need to figure out a representation for our language data such that our computer can understand it.\n",
        "\n",
        "**Question**: How can we transform our language data into something that our machine learning algorithm can work with?\n",
        "\n",
        "This question is the core of **natural language processing** (NLP)!\n",
        "\n",
        "As a first step, we need to clean our data and get rid of some stuff that we don't want to see. We'll use **regular expressions** to do this. Regular expressions are a powerful tool that perform *pattern matching*, allowing us to search a piece of text for patterns and replace all occurrences of a pattern with something else.\n",
        "\n",
        "For example, suppose we want to remove all occurrences of the letter \"X\" from a block of text (for whatever reason). This is the same as replacing the letter \"X\" with the empty string \"\". We can use the function `re.sub` to do this in Python:\n",
        "\n",
        "```\n",
        "text = re.sub(r\"X\", \"\", text)\n",
        "```\n",
        "\n",
        "**Question**: What are the arguments that we need to pass in to `re.sub`?\n",
        "\n",
        "**Exercise**: Use the function `re.sub` to get rid of all occurrences of \"\\n\" and all occurrences of \"\\xa0\" from our data. For context, these are both forms of whitespace which clog up our data unnecessarily.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PFqVK23i1c5"
      },
      "source": [
        "def preprocess_text(phrase): \n",
        "  phrase = re.sub(r\"\\xa0\", \"\", phrase) # removes \"\\xa0\"\n",
        "  phrase = re.sub(r\"\\n\", \"\", phrase) # removes \"\\n\"\n",
        "  phrase = re.sub(\"[.]{1,}\", \".\", phrase) # removes duplicate \".\"s\n",
        "  phrase = re.sub(\"[ ]{1,}\", \" \", phrase) # removes duplicate spaces\n",
        "\n",
        "  return phrase"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRoJVlLg8Luo"
      },
      "source": [
        "Now, run this next code cell to use your function to clean up our text!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI2C3NXjf-Fu",
        "cellView": "both"
      },
      "source": [
        "X = X.apply(preprocess_text)\n",
        "y = y.apply(preprocess_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1Ax45xRlz0z"
      },
      "source": [
        "Now that we've cleaned up our text, let's see how many sentences long each person's question is and how many sentences long each therapist's response is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sUmCYSzl6cs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "e235baaf-92fd-47a9-ea30-22465a021173"
      },
      "source": [
        "#@title Run this cell to plot the lengths of questions and answers, in sentences\n",
        "question_lengths, answer_lengths = [], []\n",
        "\n",
        "for (question, answer) in zip(X, y): \n",
        "  # split by \".\"\n",
        "  question_arr = question.split(\".\")\n",
        "  answer_arr = answer.split(\".\")\n",
        "\n",
        "  # get length\n",
        "  length_question = len(question_arr)\n",
        "  length_answer = len(answer_arr)\n",
        "\n",
        "  # add to array\n",
        "  question_lengths.append(length_question)\n",
        "  answer_lengths.append(length_answer)\n",
        "\n",
        "# Display the plot\n",
        "plt.hist(question_lengths, color = \"red\", alpha = 0.5)\n",
        "plt.hist(answer_lengths, color = \"blue\", alpha = 0.2)\n",
        "plt.title(\"Lengths of questions (in red) and answers (in blue)\")\n",
        "plt.axvline(np.mean(question_lengths), color = \"red\")\n",
        "plt.axvline(np.mean(answer_lengths), color = \"blue\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPg6FIhymTr8"
      },
      "source": [
        "####Discussion\n",
        "\n",
        "1. In the plot above, what do the red bars indicate? What do the blue bars indicate?\n",
        "2. The vertical lines in the plot above indicate average lengths. What is the average length of a question? What is the average length of an answer?\n",
        "3. Do people's questions or therapists' responses tend to be longer? Why might this be the case? How do you think this might affect our chatbot?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shuCs-fZmfRa"
      },
      "source": [
        "### Splitting up our questions and answers\n",
        "\n",
        "There's a little more preprocessing we need to do however! We want to keep our phrases relatively short; however, some of the questions and answers in our dataset are several sentences long.\n",
        "\n",
        "To solve this problem, we'll split up each question and each answer into their constituent sentences. We'll then pair the first sentence of the question with the first sentence of the answer, the second sentence of the question with the second sentence of the answer, and so on until we can't form any more pairs.\n",
        "\n",
        "For example, suppose we have the following question-answer pair:\n",
        "> **Q**: \"I am not feeling well today. I feel sad.\"\n",
        "\n",
        "> **A**: \"Tell me more about how you feel. What have you been up to today?\"\n",
        "\n",
        "First, we would split up the question into its constituent sentences, resulting in `[\"I am not feeling well today.\", \"I feel sad.\"]`. Similarly, we would split up the answer into its constituent sentences, resulting in `[\"Tell me more about how you feel.\", \"What have you been up to today?\"]`. Finally, we would pair each sentence of the question with its corresponding sentence of the answer, ultimately resulting in two separate question-answer pairs:\n",
        "> **Q**: \"I am not feeling well today.\"\n",
        "\n",
        "> **A**: \"Tell me more about how you feel.\"\n",
        "\n",
        "and\n",
        "\n",
        "> **Q**: \"I feel sad.\"\n",
        "\n",
        "> **A**: \"What have you been up to today?\"\n",
        "\n",
        "**Exercise**: Fill in the missing code blocks in the following cell to loop through each question and answer pair, split up each question and answer into their constituent sentences, and pair up each sentence of the question with its corresponding sentence of the answer.\n",
        "\n",
        "**Hint**: To split text, check out the `split` function.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH29Np0Kd81n"
      },
      "source": [
        "question_answer_pairs = []\n",
        "\n",
        "MAX_LENGTH = 100 # the maximum length for our sequences\n",
        "\n",
        "for (question, answer) in zip(X, y):\n",
        "  question = preprocess_text(question) \n",
        "  answer = preprocess_text(answer)\n",
        "\n",
        "  # split up question and answer into their constituent sentences\n",
        "\n",
        "  question_arr = question.split('.') ## YOUR CODE HERE\n",
        "  answer_arr = answer.split('.') ## YOUR CODE HERE\n",
        "\n",
        "  # get the maximum number of question/answer pairs we can form,\n",
        "  # which will be the shorter of len(question_arr) and len(answer_arr)\n",
        "\n",
        "  max_sentences = min(len(question_arr), len(answer_arr)) ## YOUR CODE HERE\n",
        "\n",
        "  for i in range(max_sentences):\n",
        "    q_a_pair = []\n",
        "\n",
        "    # get maximum sentence length\n",
        "    max_q_length = min(MAX_LENGTH, len(question_arr[i]))\n",
        "    max_a_length = min(MAX_LENGTH, len(answer_arr[i]))\n",
        "\n",
        "    # append question, answer to pair (e.g,. first sentence of question + first sentence of answer, etc.)\n",
        "    question_to_append = question_arr[i][0:max_q_length]\n",
        "    q_a_pair.append(question_to_append)\n",
        "\n",
        "    answer_to_append = \"<START> \" + answer_arr[i][0:max_a_length] + \" <END>\"\n",
        "    q_a_pair.append(answer_to_append)\n",
        "\n",
        "    question_answer_pairs.append(q_a_pair)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RgFlmiGm8vk"
      },
      "source": [
        "###Tokenizing our data\n",
        "\n",
        "Now that we've preprocessed our text, let's start turning it into a form that our machines can interpret. **Tokenization** is the process of turning our sentences into a list of individual tokens, like words. For example:\n",
        "\n",
        "1. Pre-tokenization: \"Hello, I really like computers\"\n",
        "2. Post-tokenization: [\"Hello,\" , \"I\", \"really\", \"like\", \"computers\"]\n",
        "\n",
        "**Question**: How can we tokenize sentences?\n",
        "\n",
        "**Exercise**: Write a function to tokenize sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr69eyU9yaGW"
      },
      "source": [
        "def tokenize(sentence):\n",
        "  # tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
        "  # tokens = tokenizer.tokenize(sentence)\n",
        "  # return tokens\n",
        "  tokens = sentence.split(\" \")\n",
        "  return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UZGD07cnEM8",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5348c67c-8aea-4f8b-eb4b-0519111a048d"
      },
      "source": [
        "#@title Enter a sentence to test your tokenization function\n",
        "\n",
        "sentence = \"I love Inspirit AI!\" #@param {type:\"string\"}\n",
        "\n",
        "# split sentence by space\n",
        "split_sentence = tokenize(sentence)\n",
        "print(f\"The original sentence: {sentence}\")\n",
        "print(f\"The tokenized sentence: {split_sentence}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original sentence: I love Inspirit AI!\n",
            "The tokenized sentence: ['I', 'love', 'Inspirit', 'AI!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFW5ckJ7nn5T"
      },
      "source": [
        "###Padding our data\n",
        "\n",
        "For our neural network model to work, our input sentences must all be of the same length. However, as we've seen, some sentences are longer than others! Our sentences need to be all the same length, but some sentences are longer than others.\n",
        "\n",
        "So what can we do? If a sentence is too long, we will trim it. If a sentence is too short, we'll add some **padding tokens**.\n",
        "\n",
        "We also need to add **start tokens** and **end tokens**, which tell our program when a sentence is starting and ending respectively.\n",
        "\n",
        "**Question**: Why do we need start and end tokens? (Hint: consider what might happen if a sentence is too long and is trimmed!)\n",
        "\n",
        "####Example\n",
        "\n",
        "Let's run through how we might pad an example sentence. Suppose we have:\n",
        "\n",
        "`\"This is a really cool sentence!\"`\n",
        "\n",
        "First, we add our start and end tokens, which we represent with `\"<SOS>\"` and `\"<EOS>\"`:\n",
        "\n",
        "`\"<SOS> This is a really cool sentence! <EOS>\"`\n",
        "\n",
        "Suppose we want sentences to be 10 tokens long. Since our sentence is only 8 tokens long, we need to we add padding tokens, which we represent with `\"<pad>\"`:\n",
        "\n",
        "`\"<SOS> This is a really cool sentence! <EOS> <pad> <pad>\"`\n",
        "\n",
        "Alternatively, suppose we wanted sentences to be 6 tokens long. Then, we would trim our sentence (note: keep the \\<EOS\\>!):\n",
        "\n",
        "`\"<SOS> This is a really <EOS>\"`\n",
        "\n",
        "**Exercise**: Fill in the missing code blocks in the function below to add these features to our sentence data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SIJx7SZnt-N"
      },
      "source": [
        "def tokenize_and_pad(sentence, max_len):\n",
        "  # \"\"\"\n",
        "  #   Tokenizes our sentence (splits up the individual words), adds <SOS> and <EOS> tags, \n",
        "  #   and, if it's too short, add, padding at the end (before <EOS>)\n",
        "  # \"\"\"\n",
        "  # sentence_arr = tokenize(sentence)\n",
        "\n",
        "  # diff = max_len - (len(sentence_arr) + 2)\n",
        "  # tokenized_sentence = []\n",
        "  # sos = ['<SOS>']\n",
        "  # eos = ['<EOS>']\n",
        "  # pad = ['<pad>']\n",
        "\n",
        "  # if diff > 0: # if too short, add padding + start/end tokens\n",
        "  #   ## BEGIN YOUR CODE HERE\n",
        "  #   # tokenized_sentence.append(sos)\n",
        "  #   # for word in sentence_arr:\n",
        "  #   #   tokenized_sentence.append(word)\n",
        "  #   # tokenized_sentence.append(eos)\n",
        "  #   # for i in range(diff):\n",
        "  #   #   tokenized_sentence.append(pad)\n",
        "  #   ## END YOUR CODE HERE\n",
        "    \n",
        "  #   tokenized_sentence = sos + sentence_arr + eos + (pad * diff) \n",
        "\n",
        "  # elif diff == 0: # if right length, just add start/end tokens\n",
        "  #   ## BEGIN YOUR CODE HERE\n",
        "  #   # tokenized_sentence.append(sos)\n",
        "  #   # for word in sentence_arr:\n",
        "  #   #   tokenized_sentence.append(word)\n",
        "  #   # tokenized_sentence.append(eos)\n",
        "  #   ## END YOUR CODE HERE\n",
        "\n",
        "  #   tokenized_sentence = sos + sentence_arr + eos\n",
        "\n",
        "  # else: # if too long, add start/end tokens, truncate\n",
        "  #   ## BEGIN YOUR CODE HERE\n",
        "  #   # tokenized_sentence.append(sos)\n",
        "  #   # for i in range(len(sentence_arr) + diff):\n",
        "  #   #   tokenized_sentence.append(sentence_arr[i])\n",
        "  #   # tokenized_sentence.append(eos)\n",
        "  #   ## END YOUR CODE HERE\n",
        "\n",
        "  #   tokenized_sentence = [\"<SOS>\"] + sentence_arr[0:diff] + [\"<EOS>\"]\n",
        "\n",
        "\n",
        "  # return tokenized_sentence\n",
        "  def tokenize_and_pad(sentence, max_len):\n",
        "    \"\"\"\n",
        "      Tokenizes our sentence (splits up the individual words), adds <SOS> and <EOS> tags, \n",
        "      and, if it's too short, add, padding at the end (before <EOS>)\n",
        "    \"\"\"\n",
        "\n",
        "    sentence_arr = sentence.split(\" \")\n",
        "\n",
        "    diff = max_len - (len(sentence_arr) + 2)\n",
        "\n",
        "    if diff > 0: # if too short, add padding + start/end tokens\n",
        "      tokenized_sentence = [\"<SOS>\"] + sentence_arr + [\"<EOS>\"] + ([\"<pad>\"] * diff) \n",
        "    elif diff == 0: # if right length, just add start/end tokens\n",
        "      tokenized_sentence = [\"<SOS>\"] + sentence_arr + [\"<EOS>\"]\n",
        "    else: # if too long, add start/end tokens, truncate\n",
        "      tokenized_sentence = [\"<SOS>\"] + sentence_arr[0:diff] + [\"<EOS>\"]\n",
        "\n",
        "    return tokenized_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBuC2jplnzso",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94febb90-0b7b-4971-fb2c-63280e4f6d9e"
      },
      "source": [
        "#@title Run this code chunk to see your function at work! Enter a sentence and a maximum length and see how it looks when tokenized and given padding\n",
        "\n",
        "sentence = \"Hello from the other side!\" #@param {type:\"string\"}\n",
        "max_len =  6#@param {type:\"integer\"}\n",
        "\n",
        "print(tokenize_and_pad(sentence, max_len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "derYzyw4oGo-"
      },
      "source": [
        "Phew, that was a lot! Cleaning and preparing a dataset is one of the most important parts of creating a good machine learning model. After all, a good model is nothing without good data! Speaking of which, it's about time we begin designing our model...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6DmaqOifoPJ"
      },
      "source": [
        "##Modeling our data with a Sequential Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZu65KcbqhaA"
      },
      "source": [
        "### Review: What are neural networks?\n",
        "\n",
        "By now, you've had the chance to use regular **neural networks**! Neural networks are a machine learning model loosely modeled after the human nervous system. They are commonly used for a variety of tasks, such as facial recognition, language generation, stock prediction, and more!\n",
        "\n",
        "Neural networks operate by stacking layers and layers of **neurons**, each of which detects a portion of the input. However, there are some problems with traditional neural networks that we run into when trying to use them for natural language processing.\n",
        "\n",
        "![link](https://cdn.kastatic.org/ka-perseus-images/53bcace05b8a222f57f0c07f86f92354c4614d01.svg)\n",
        "\n",
        "For example, let's take a look at the above neural network.\n",
        "\n",
        "**Question**: First of all, what does this model assume about the length of the input text? What about the length of the output text?\n",
        "\n",
        "**Question**: Word order matters. For example, \"man ate chicken\" and \"chicken ate man\" are quite distinct! Furthermore, each word gives crucial information for the next one. Does this model capture those relationships?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47Kp2f_zoE_Y"
      },
      "source": [
        "###Recurrent Neural Networks\n",
        "\n",
        "In order to resolve these problems, we must explore a different type of neural network, one that can handle *sequence data*, called a **recurrent neural network** (RNN).\n",
        "\n",
        "![link](https://cdn-images-1.medium.com/freeze/max/1000/1*SKGAqkVVzT6co-sZ29ze-g.png?q=20)\n",
        "\n",
        "RNNs are designed for sequence data: the model processes its input and products output *in order*.\n",
        "\n",
        "So how do RNNs work?\n",
        "\n",
        "In brief, as an RNN processes its input, it maintains a **hidden state vector** to remember some of what it's seen so far.\n",
        "\n",
        "**Question**: For text generation, what should an RNN remember?\n",
        "\n",
        "With each new input, the model uses the old hidden state to compute a new hidden state and a new output.\n",
        "\n",
        "For this type of question, where we try to predict what comes next, based off of what came before it, RNNs work really well.\n",
        "\n",
        "**Optional**: For another look into RNNs, check out [this Medium article](https://towardsdatascience.com/recurrent-neural-networks-d4642c9bc7ce)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOTIR7hcoWr2"
      },
      "source": [
        "###Long-Short Term Memory Networks\n",
        "\n",
        "For our notebook, we'll actually use a specialized type of RNN called a **long-short term memory network** (LSTM). An LSTM is typically more accurate than a basic RNN, especially for longer sequences, because it also maintains a form of *long-term memory* in addition to the *short-term memory* which an RNN maintains. Consequently, it is able to remember important pieces of information for a long period of time, whereas an RNN is only able to maintain information for a short period of time.\n",
        "\n",
        "We won't go into the nitty-gritty of LSTMs since they are somewhat complex, but if you want a deeper understanding of LSTMs, please check out the Challenge Exercise portion of this notebook.\n",
        "\n",
        "**Question**: Why is an RNN only able to maintain information for a short period of time? (hint: think about what happens to information stored in the hidden state vector as we continue writing to the hidden state vector!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxN3Jn9yoKk3"
      },
      "source": [
        "###The Seq2Seq model design\n",
        "\n",
        "We'll put two LSTMs together to create our model, in a type of design called **Seq2Seq**. The Seq2Seq design is used in scenarios where one wants to model both what someone is telling the model and what the model should say in response. This allows the model to process the entire input before formulating a response, which is very useful for language data. This seems like a great model to use for our chatbot!\n",
        "\n",
        "The Seq2Seq model design has two main components:\n",
        "1. One LSTM which processes the input and encodes the information into word embeddings. We call this LSTM the **encoder**.\n",
        "2. One LSTM which takes the word embeddings and decodes them into a response. We call this LSTM the **decoder**.\n",
        "\n",
        "![link](http://4.bp.blogspot.com/-aArS0l1pjHQ/Vjj71pKAaEI/AAAAAAAAAxE/Nvy1FSbD_Vs/s1600/2TFstaticgraphic_alt-01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KaqxDYJrANC"
      },
      "source": [
        "### Creating our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UE-p0u9NHqY"
      },
      "source": [
        "#@title Run this cell to do some initialization\n",
        "\n",
        "# re-create questions, answers\n",
        "questions = [arr[0] for arr in question_answer_pairs]\n",
        "answers = [arr[1] for arr in question_answer_pairs]\n",
        "\n",
        "target_regex = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\n\\'0123456789'\n",
        "tokenizer = Tokenizer(filters=target_regex)\n",
        "tokenizer.fit_on_texts(questions + answers)\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "\n",
        "# create encoder input data\n",
        "tokenized_questions = tokenizer.texts_to_sequences(questions)\n",
        "maxlen_questions = max([len(x) for x in tokenized_questions])\n",
        "#encoder_input_data = pad_sequences(tokenized_questions,\n",
        "#                                   maxlen=maxlen_questions,\n",
        "#                                   padding='post')\n",
        "\n",
        "# create decoder input data\n",
        "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
        "maxlen_answers = max([len(x) for x in tokenized_answers])\n",
        "#decoder_input_data = pad_sequences(tokenized_answers,\n",
        "#                                   maxlen=maxlen_answers,\n",
        "#                                   padding='post')\n",
        "\n",
        "# create decoder output data\n",
        "#for i in range(len(tokenized_answers)):\n",
        "#    tokenized_answers[i] = tokenized_answers[i][1:]\n",
        "#padded_answers = pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding='post')\n",
        "#decoder_output_data = to_categorical(padded_answers, VOCAB_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcoce08NzBz9"
      },
      "source": [
        "**Exercise**: Fill in the missing code blocks in the cell below to complete the Seq2Seq model design.\n",
        " * First, we need to process our input through our encoder LSTM. In the first missing code block, create an `LSTM` layer with 200 units which returns the last state (`return_state=True`). Store this layer in `enc_lstm`.\n",
        " * Next, we need to process our embeddings through our decoder LSTM. In the second missing code block, create an `LSTM` layer with 200 units which returns the last state (`return_state=True`) *and* returns the last output (`return_sequences=True`). Store this layer in `dec_lstm`.\n",
        " * Finally, we want to run the output of our decoder through a fully connected neural network. In the third missing code block, create a `Dense` layer with `VOCAB_SIZE` units and a softmax activation function. Store this layer in `dec_dense`.\n",
        "\n",
        "**Hint**: Check the Keras documentation for details on [the `LSTM` layer](https://keras.io/api/layers/recurrent_layers/lstm/) and for details on [the `Dense` layer](https://keras.io/api/layers/core_layers/dense/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kar6ZF4NNdct",
        "cellView": "both"
      },
      "source": [
        "enc_inputs = Input(shape=(None,))\n",
        "enc_embedding = Embedding(VOCAB_SIZE, 200, mask_zero=True)(enc_inputs)\n",
        "enc_lstm = LSTM(200, return_state=True)\n",
        "_, state_h, state_c = enc_lstm(enc_embedding)\n",
        "enc_states = [state_h, state_c]\n",
        "\n",
        "dec_inputs = Input(shape=(None,))\n",
        "dec_embedding = Embedding(VOCAB_SIZE, 200, mask_zero=True)(dec_inputs)\n",
        "dec_lstm = LSTM(200, return_state=True, return_sequences=True)\n",
        "dec_outputs, _, _ = dec_lstm(dec_embedding, initial_state=enc_states)\n",
        "\n",
        "dec_dense = Dense(VOCAB_SIZE, activation=softmax)\n",
        "output = dec_dense(dec_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3u8HBl12xsJ"
      },
      "source": [
        "Great job! You've created a Seq2Seq model.\n",
        "\n",
        "**Exercise**: Next, use `model.compile()` to compile your model with an `RMSprop` optimizer and a `categorical_crossentropy` loss function. Then print out a summary of your model using `model.summary()`.\n",
        "\n",
        "**Hint**: Check the Keras documentation for [details on `model.compile`](https://keras.io/api/models/model_training_apis/#compile-method)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAYeutokzKnq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e65f8766-c686-44e4-a49d-ecc33be79e37"
      },
      "source": [
        "model = Model([enc_inputs, dec_inputs], output)\n",
        "model.compile(optimizer=RMSprop(), loss='categorical_crossentropy')\n",
        "model.summary()\n",
        "## YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 200)    1617000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 200)    1617000     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 200),  320800      ['embedding_1[0][0]',            \n",
            "                                 (None, 200),                     'lstm[0][1]',                   \n",
            "                                 (None, 200)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 8085)   1625085     ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,500,685\n",
            "Trainable params: 5,500,685\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6OojFoyNlgG"
      },
      "source": [
        "#@title Run this code chunk to do some clean-up\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AglimD2QNtzR"
      },
      "source": [
        "###\"Training\" our model\n",
        "\n",
        "Alright, our model is ready to go!\n",
        "\n",
        "Normally, we would do training now. However, in our case, we'll use a pre-trained model instead. If we were to train our model from scratch, it would take *waaaay* too long to train -- much longer than we have classtime for!\n",
        "\n",
        "For this reason, it is typical for large tech companies with more resources to train models such as Seq2Seq on large amounts of data and then release the weights of their trained models to the public. Then others, such as ourselves, can take these trained models, train just a couple layers on top of them to learn domain-specific knowledge, and then have a fully-functional model all trained and ready to go!\n",
        "\n",
        "**Exercise**: Load a set of pre-trained weights into our model. To do this, you can use the function `model.load_weights()`.\n",
        "\n",
        "**Hint**: As usual, check the Keras documentation for [details on model.load_weights](https://www.tensorflow.org/api_docs/python/tf/keras/Model#load_weights)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UJpKKAEPS2m"
      },
      "source": [
        "# The filepath to our pre-trained weights\n",
        "path_to_weight = \"chatbot_seq2seq_v3.h5\"\n",
        "model.load_weights(path_to_weight)\n",
        "## YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veoP8fSePXyL"
      },
      "source": [
        "## Evaluation -- so how's our chatbot looking?\n",
        "\n",
        "Model designed, check. Model trained, \"check\". You've successfully created a fully-functional and fully-trained model -- awesome! All that's left to do now is test out our model and see how it does!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrRpDyRpPdzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aee5a810-0bc2-4fcb-8dbe-0670b89ac52d"
      },
      "source": [
        "#@title Run this cell to do some initialization\n",
        "def make_inference_models():\n",
        "    dec_state_input_h = Input(shape=(200,))\n",
        "    dec_state_input_c = Input(shape=(200,))\n",
        "    dec_states_inputs = [dec_state_input_h, dec_state_input_c]\n",
        "    dec_outputs, state_h, state_c = dec_lstm(dec_embedding,\n",
        "                                             initial_state=dec_states_inputs)\n",
        "    dec_states = [state_h, state_c]\n",
        "    dec_outputs = dec_dense(dec_outputs)\n",
        "    dec_model = Model(\n",
        "        inputs=[dec_inputs] + dec_states_inputs,\n",
        "        outputs=[dec_outputs] + dec_states)\n",
        "    print('Inference decoder:')\n",
        "    dec_model.summary()\n",
        "    print('Inference encoder:')\n",
        "    enc_model = Model(inputs=enc_inputs, outputs=enc_states)\n",
        "    enc_model.summary()\n",
        "    return enc_model, dec_model\n",
        "\n",
        "def str_to_tokens(sentence: str):\n",
        "    words = sentence.lower().split()\n",
        "    tokens_list = list()\n",
        "    for current_word in words:\n",
        "        result = tokenizer.word_index.get(current_word, '')\n",
        "        if result != '':\n",
        "            tokens_list.append(result)\n",
        "    return pad_sequences([tokens_list],\n",
        "                         maxlen=maxlen_questions,\n",
        "                         padding='post')\n",
        "    \n",
        "enc_model, dec_model = make_inference_models()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference decoder:\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 200)    1617000     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 200),  320800      ['embedding_1[0][0]',            \n",
            "                                 (None, 200),                     'input_3[0][0]',                \n",
            "                                 (None, 200)]                     'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 8085)   1625085     ['lstm_1[2][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,562,885\n",
            "Trainable params: 3,562,885\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Inference encoder:\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 200)         1617000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 [(None, 200),             320800    \n",
            "                              (None, 200),                       \n",
            "                              (None, 200)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,937,800\n",
            "Trainable params: 1,937,800\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9pEGmRgiyI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f38977-4ccf-4b66-ae29-189f893e5e16",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell and type your question to see what our chatbot says!\n",
        "\n",
        "question = \"i need some help\" #@param {type:\"string\"}\n",
        "for _ in range(1):\n",
        "    states_values = enc_model.predict(\n",
        "        str_to_tokens(question))\n",
        "    empty_target_seq = np.zeros((1, 1))\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
        "    stop_condition = False\n",
        "    decoded_translation = ''\n",
        "    while not stop_condition:\n",
        "        dec_outputs, h, c = dec_model.predict([empty_target_seq]\n",
        "                                              + states_values)\n",
        "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
        "        sampled_word = None\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if sampled_word_index == index:\n",
        "                if word != 'end':\n",
        "                    decoded_translation += ' {}'.format(word)\n",
        "                sampled_word = word\n",
        "\n",
        "        if sampled_word == 'end' \\\n",
        "                or len(decoded_translation.split()) \\\n",
        "                > maxlen_answers:\n",
        "            stop_condition = True\n",
        "\n",
        "        empty_target_seq = np.zeros((1, 1))\n",
        "        empty_target_seq[0, 0] = sampled_word_index\n",
        "        states_values = [h, c]\n",
        "\n",
        "    print(decoded_translation)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " i m sorry you have been married with your partner to give him to be your doctor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM8R3_Cw63KH"
      },
      "source": [
        "####Discussion\n",
        "\n",
        "1. How did our pretrained model do? Do you think it's an improvement over our ELIZA chatbot from last notebook? Why or why not?\n",
        "2. Are there some responses that surprise you?\n",
        "3. Are there certain types of mistakes that the program keeps making? \n",
        "4. How do you think we can improve our program? As you can see, it's still definitely a work in progress, and we'll work on improving it in our next notebook. Can you think of some ways that we could go about trying to improve it?\n",
        "\n",
        "Food for thought:\n",
        "  - What would happen if we gave our chatbot more examples to learn from?\n",
        "  - This program that we're using was trained for 100 epochs. Do you think that we should train it for longer? How long is long enough?\n",
        "  - Should we use more neurons in our neural network and make it bigger?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxwu4tbTlcWp"
      },
      "source": [
        "###Conclusion\n",
        "\n",
        "Congrats! Today, you've built an even better chatbot, one that's powered by artificial intelligence and machine learning. Hopefully you can see that our chatbot is looking a little bit more and more like the chatbots and voice assistants that we take for granted today, such as Alexa and Echo. You've learned about the key technologies that have driven modern chatbots; most of the current cutting-edge work in language generation and in chatbots is some improvement on the programs that you've learned about today. In our next notebook, we'll look at even more cutting-edge machine learning techniques in order to make our chatbots perform better, while also tying back our chatbot to our question of mental health and thinking about how well our chatbots would work in that context. Till next time!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DatD-SORn5k1"
      },
      "source": [
        "###Challenge Exercise: How do LSTMs actually work?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fcs9AEes2e9"
      },
      "source": [
        "#### Let's examine why LSTMs were created in the first place\n",
        "\n",
        "Regular RNNs suffer from what's called a \"vanishing gradient\". What does this mean?\n",
        "\n",
        "For example, if you gave an RNN two sentences with blanks:\n",
        "\n",
        "1. \"I loved traveling to France, where the weather was lovely and the food was extraordinary. I particularly enjoyed exploring the capital city of ____.\"\n",
        "\n",
        "2. \"I'm a person who just really enjoys traveling and trying all the good food around the world. The capital of France is _____.\"\n",
        "\n",
        "Which one do you think a typical RNN would do better at predicting?\n",
        "\n",
        "A typical RNN would do better with sentence (2) than sentence (1).\n",
        "\n",
        "Why?\n",
        "\n",
        "So here, the correct word for each of the blanks is \"Paris\", the capital of France. The key bit of information that you would've needed to see was the word \"France\". However, in sentence (1), France is in the beginning of the string, and the blank is at the end, while in sentence (2), France is near the blank. \n",
        "\n",
        "Typical RNNs place more weight on more recent information when trying to predict, say, what comes next. Functionally, this makes sense, since it's often likely that the information that helps predict what word comes next is probably the words that came just before it. However, there are definitely instances where we want our program to, say, remember what came up much earlier in a long conversation, and typical RNNs can't do that too well.\n",
        "\n",
        "![link](http://images.memes.com/meme/721858)\n",
        "\n",
        "\n",
        "LSTMs and GRUs are two similar models which are both modifications of RNNs that were designed to get around this problem. Below is a structure of an LSTM cell, which is the \"fundamental unit\" of an LSTM (similar to how the fundamental unit of a neural network is the neuron).\n",
        "\n",
        "![link](https://i.stack.imgur.com/voZql.jpg)\n",
        "\n",
        "The key takeaway here is that LSTMs can selectively \"choose\" what things to remember and what things to forget. \n",
        "\n",
        "Typical RNNs have one \"hidden unit\", which keeps track of, for example, what was said earlier in a sentence. However, this hidden unit can be heavily influenced by what it's seen more recently, and so things that were seen earlier in the sequence become \"forgotten\" as the RNN gets further along in a sentence (because as the RNN gets further along into a sentence, it \"writes over\" older information to make room for new information)\n",
        "\n",
        "For example: \n",
        "\n",
        "\"I loved traveling to France, where the weather was lovely and the food was extraordinary. I particularly enjoyed exploring the capital city of ____.\"\n",
        "\n",
        "By the time that an RNN gets to the end of this, it's already forgotten that the word \"France\" exists. It's not quite sure which words to treat as important so it's going to default by assuming that words which are later in the sequence are more important than those earlier in the sequence. \n",
        "\n",
        "However, an LSTM can \"choose\" what it remembers and what it forgets. For example, in the sequence: \n",
        "\n",
        "\"I loved traveling to France, where the weather was lovely and the food was extraordinary. I particularly enjoyed exploring the capital city of ____.\"\n",
        "\n",
        "The phrase is passed in, one word at a time. So, for example, \n",
        "\n",
        "\n",
        "\n",
        "• \"I\"\n",
        "\n",
        "• \"I loved\"\n",
        "\n",
        "• \"I loved traveling\"\n",
        "\n",
        "• \"I loved travelng to\"\n",
        "\n",
        "• \"I loved traveling to France\"\n",
        "\n",
        "Intuitively, at each step, an LSTM can look at the new word and ask \"how important is it that I remember this piece of information?\"\n",
        "\n",
        "For example, when the LSTM sees this: \n",
        "\n",
        "• \"I loved traveling to France\"\n",
        "\n",
        "The LSTM might place weight on \"traveling\" and \"France\" because those are the key themes of the sentence. When the LSTM gets to this point though in the sequence:\n",
        "\n",
        "• \"I loved traveling to France, where the weather was lovely and the food was extraordinary.\"\n",
        "\n",
        "The LSTM can still place a great deal of weight on \"traveling\" and \"France\", even though they were earlier in the sentence, because the LSTM can choose which past words are going to be important to predicting what comes next, regardless of where those words were in the sequence. \n",
        "\n",
        "#### Why is this important for us?\n",
        "\n",
        "We want a program where a person can ask a question, of any given length, and our program will be able to understand it. One thing to consider is that in mental health, it's common for people to say, upfront, what's bothering them (e.g., anxiety), and then to go on and talk about what they've been going through recently. We want our program to be robust enough so that, as people talk with our chatbot, the chatbot won't forget the main topic of conversaton (e.g, \"this person is feeling anxious\")"
      ]
    }
  ]
}